"""
script: datacube_resp_tool.py
auth: Nathan T. Stevens
org: Pacific Northwest Seismic Network
license: CC 4.0 BY
purpose: This command line utility takes a *_stachan.csv formatted file and 
  creates a StationXML file summarizing network metadata including instrument
  response for DataCube dataloggers paired with PE-6B three component geophone

development note: started working on a miniseed file list -> WFDISC.csv functionality
  that I stopped working on due to time constraints. Starting points for this functionality
  are currently preserved as commented-out blocks
"""
# import glob, 
import sys, os
from pathlib import Path
from argparse import ArgumentParser
# from obspy import read
from obspy.core.inventory import *
from obspy.clients.nrl import NRL
from pandas import read_csv

DESC = """This command line utility takes a *_stachan.csv formatted file and 
  creates a StationXML file summarizing network metadata including instrument
  response for DataCube dataloggers paired with PE-6B three component geophone"""

SENDING_INSTITUTION='PNSN'

# Main function
def main():
    # initialize command line argument parser
    parser = ArgumentParser(prog='datacube_resp_tool.py',
                            description=DESC)
    
    # stachan file flag
    parser.add_argument(
        '-s', '--stachan',
        action='store',
        required=True,
        type=str,
        dest='stachan',
        help='*_stachan.csv file containing station metadata and channel mappings'
    )

    # # Miniseed glob-able string argument (not implemented)
    # parser.add_argument(
    #     '-m','--miniseed-file',
    #     action='store',
    #     required=True,
    #     type=str,
    #     dest='globstr',
    #     help='Single miniseed file name or valid glob-able string to produce a'\
    #          'list of miniseed file name (e.g., path/to/my/station/mseed/*.pri?)'
    # )

    # Where to output StationXML file
    parser.add_argument(
        '-o', '--output-dir',
        action='store',
        required=False,
        type=str,
        dest='output_dir',
        default=Path.cwd(),
        help='Directory in which to save the station.xml file generated by this script. ' \
             'Defaults to current working directory (pathlib.Path.cwd()).'
    )

    # Parse Arguments
    args = parser.parse_args()

    # Read stachan.csv
    df = read_csv(args.stachan, dtype={'location': str})
    expected_cols = set(['network','station','location','component_code',
                         'logger_name','logger_channel',
                         'sampling_rate','gain',
                         'latitude','longitude',
                         'elevation_m','depth_m',
                         'azimuth','dip'
                        ])
    # Exit on 1 (failure) if column names don't look right
    if set(df.columns) != expected_cols:
        breakpoint()
        print(f'Provided stachan file "-s {args.stachan}" does not look like it has the right format. Exiting on 1')
        sys.exit(1)

    # Clean up location codes
    df.location = df.location.apply(lambda x: '' if not isinstance(x, str) else ( '0'+x if len(x) == 1 else x[:2]))

    # # Get list of files (not implemented)
    # file_list = glob.glob(args.globstr)

    # # Exit on 1 (failure) if no miniseed files are provided
    # if len(file_list) == 0:
    #     print(f'No files found for input "-m {args.globstr}". Exiting on 1')
    #     sys.exit(1)
    
    # Initialize Nominal Response Library Client
    client = NRL()
    # Initialize query cache
    cache = {}

    # Initialize inventory
    inv = Inventory(networks = [], source=SENDING_INSTITUTION)
    # Iterate across network codes
    for ncode in df.network.unique():
        net = Network(
            code = ncode,
            stations = [],
            description = f'Network {ncode}'
        )
        # Subset stachan by network code
        _df = df[df.network == ncode]
        # Iterate across station codes
        for scode in _df.station.unique():
            # Subset the subset by station code
            __df = _df[_df.station == scode]
            # Populate station object
            sta = Station(
                code = scode,
                latitude = __df.iloc[0].latitude,
                longitude = __df.iloc[0].longitude,
                elevation = __df.iloc[0].elevation_m,
            )
            # Iterate across this station's channels
            for _, row in __df.iterrows():
                ccode = get_SEED_channel_code(sampling_rate = row.sampling_rate, 
                                              component_code = row.component_code)
                # Create channel object
                cha = Channel(
                    code = ccode,
                    location_code = row.location,
                    latitude = row.latitude,
                    longitude = row.longitude,
                    elevation = row.elevation_m,
                    depth = row.depth_m,
                    azimuth = row.azimuth,
                    dip = row.dip,
                    sample_rate = row.sampling_rate
                )
                # Get response
                # Populate NRL query key-word arguments locally
                resp_kwargs = get_nrl_kwargs(sampling_rate = row.sampling_rate,
                                             gain = row.gain)
                
                # Check if response query is already cached
                if row.sampling_rate in cache.keys():
                    if row.gain in cache[row.sampling_rate].keys():
                        # Get response from cache
                        resp = cache[row.sampling_rate][row.gain]
                    else:
                        # Get response from NRL
                        resp = client.get_response(**resp_kwargs)
                        # Update Cache
                        cache[row.sampling_rate].update({row.gain: resp})
                else:
                    # Get response from NRL
                    resp = client.get_response(**resp_kwargs)
                    # Update cache
                    cache.update({row.sampling_rate: {row.gain: resp}})
                
                # Attach response
                cha.response = resp
                # Attach channel to station
                sta.channels.append(cha)
            # Attach station to network
            net.stations.append(sta)
        # Attach network to inventory
        inv.networks.append(net)

    # Write inventory to output file
    os.makedirs(str(Path(args.output_dir)), exist_ok=True)

    inv.write(Path(args.output_dir) / 'station.xml', format='STATIONXML')
    # return inventory
    return inv

### SUBROUTINES ###

def get_nrl_kwargs(sampling_rate=100, gain=16):
    """Populate Nominal Response Library query arguments for
    DataCube + PE-6B instrumentation set to a specific sampling
    rate and preamplification gain

    :param sampling_rate: sampling rate value, defaults to 100 [sps]
        accepted: 50, 100, 200, 400, 800
    :type sampling_rate: int, optional
    :param gain: preamplification gain value, defaults to 16 [dB]
        accepted: 1, 2, 4, 8, 16, 32, 64
    :type gain: int, optional
    :return nrl_response_kwargs: sensor and datalogger keys for  :meth:`obspy.client.nrl.NRL.get_response`
    :rtype nrl_response_kwargs: dict
    """    

    # Fresh definition of arguments
    sensor_keys = ['manufacturer','model','coil_resistance','shunt_resistance']
    sensor_vals = ['SensorNederland', 'PE-6', '375', 'None']

    sensor = dict(zip(sensor_keys, sensor_vals))

    datalogger_keys = ['manufacturer','model','preamp_gain','sampling_rate']
    datalogger_vals = ['DiGOS/Omnirecs','DATACUBE','1','100']

    datalogger = dict(zip(datalogger_keys, datalogger_vals))

    preamp_gains = [1,2,4,8,16,32,64]
    sampling_rates = [50,100,200,400,800]

    # Update or fail on sampling_rate setting
    if sampling_rate not in sampling_rates:
        print(f'sampling_rate value {sampling_rate} invalid.')
        print('Accepted values: 50, 100, 200, 400, 800. Must be type integer')
        print('Exiting on 1')
        sys.exit(1)
    else:
        datalogger.update({'sampling_rate': f'{sampling_rate:d}'})
    
    # Update or fail on gain setting
    if gain not in preamp_gains:
        print(f'gain value {gain} invalid.')
        print('Accepted values: 1, 2, 4, 8, 16, 32, 64. Must be type integer')
        print('Exiting on 1')
        sys.exit(1)
    else:
        datalogger.update({'preamp_gain': f'{gain:d}'})
    
    # Compose output as deep copy to prevent mutation/memory bleed
    nrl_response_kwargs = {'sensor_keys': sensor.copy().values(), 
                           'datalogger_keys': datalogger.copy().values()}

    return nrl_response_kwargs


def get_SEED_channel_code(sampling_rate=100,
                          instrument_type='geophone',
                          component_code='Z'):
    """Populate the channel code using the SEED channel naming convention
    for geophones and accelerometers (short period instrumentation)

    Note: This is an incomplete implementation. See the EarthScope/IRIS
    web-page for full information:

    https://ds.iris.edu/ds/nodes/dmc/data/formats/seed-channel-naming/

    :param sampling_rate: sampling rate in samples per second, defaults to 100 [sps]
    :type sampling_rate: int, optional
    :param instrument_type: instrument type, defaults to 'geophone'
        accepted values: 'geophone', 'accelerometer'
    :type instrument_type: str, optional
    :param component_code: component code, defaults to 'Z'
    :type component_code: str or int-like, optional
        Accepts any single character string
        Converts int-like values to string and takes the first character in the
        string as the component code.
         e.g., component_code = 101 --> 1
               component_code = 3.2 --> 3
    :return: channel code
    :rtype: str
        Default values return a channel code: 'EPZ'
        In english: "Record with short period sampling by a geophone vertical component" 
    """    
    sr = sampling_rate
    if sr <= 0:
        print('Must use non-negative sampling_rate values. Exiting on 1')
        sys.exit(1)
    elif 0 < sr < 10:
        print('Medium period and longer period sampling rates not supported. Exiting on 1')
        sys.exit(1)
    elif 10 <= sr < 80:
        _b = 'S'
    elif 80 <= sr < 250:
        _b = 'E'
    elif 250 <= sr < 1000:
        _b = 'D'
    elif 1000 <= sr <= 5000:
        _b = 'G'
    else:
        print(f'sampling_rate {sampling_rate} not implemented by this utility. Max value accepted is 5000')
    

    insttypes = {'geophone': 'P',
            'accelerometer': 'N'}

    _i = insttypes[instrument_type]
    if isinstance(component_code, str):
        _c = component_code[0].upper()
    elif isinstance(component_code, (int, float)):
        _c = f'{int(component_code):d}'[0]
    else:
        print(f'invalid component code value "{component_code}". Exiting on 1')
        sys.exit(1)
    
    ccode = _b + _i + _c
    return ccode
    
if __name__ == '__main__':
    inv = main()